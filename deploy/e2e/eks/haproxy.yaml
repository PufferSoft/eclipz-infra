apiVersion: v1
kind: Pod
metadata:
  annotations:
    checksum/config: 1c1492c9767a6c7059b2dc6ec5b7ea0f0d18bec6f17664a4814c21bb00372c25
    kubernetes.io/psp: eks.privileged
    prometheus.io/path: /metrics
    prometheus.io/port: "9101"
    prometheus.io/scrape: "true"
  creationTimestamp: "2022-10-17T15:58:00Z"
  generateName: argo-cd-redis-ha-haproxy-75fb577466-
  labels:
    app: redis-ha-haproxy
    pod-template-hash: 75fb577466
    release: argo-cd
    revision: "1"
  name: argo-cd-redis-ha-haproxy-75fb577466-7z7dp
  namespace: argocd
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: ReplicaSet
    name: argo-cd-redis-ha-haproxy-75fb577466
    uid: 9ec38d97-e3c8-405a-86e0-a307320928aa
  resourceVersion: "1773"
  uid: e748f0ec-0455-4ed5-a85c-91a67ae28ae4
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: redis-ha-haproxy
            release: argo-cd
            revision: "1"
        topologyKey: kubernetes.io/hostname
  containers:
  - image: haproxy:2.0.4
    imagePullPolicy: IfNotPresent
    lifecycle: {}
    livenessProbe:
      failureThreshold: 3
      httpGet:
        path: /healthz
        port: 8888
        scheme: HTTP
      initialDelaySeconds: 5
      periodSeconds: 3
      successThreshold: 1
      timeoutSeconds: 1
    name: haproxy
    ports:
    - containerPort: 6379
      name: redis
      protocol: TCP
    - containerPort: 9101
      name: metrics-port
      protocol: TCP
    readinessProbe:
      failureThreshold: 3
      httpGet:
        path: /healthz
        port: 8888
        scheme: HTTP
      initialDelaySeconds: 5
      periodSeconds: 3
      successThreshold: 1
      timeoutSeconds: 1
    resources: {}
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /usr/local/etc/haproxy
      name: data
    - mountPath: /run/haproxy
      name: shared-socket
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-rwnn5
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  initContainers:
  - args:
    - /readonly/haproxy_init.sh
    command:
    - sh
    image: haproxy:2.0.4
    imagePullPolicy: IfNotPresent
    name: config-init
    resources: {}
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /readonly
      name: config-volume
      readOnly: true
    - mountPath: /data
      name: data
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-rwnn5
      readOnly: true
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext:
    fsGroup: 1000
    runAsNonRoot: true
    runAsUser: 1000
  serviceAccount: argo-cd-redis-ha-haproxy
  serviceAccountName: argo-cd-redis-ha-haproxy
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - configMap:
      defaultMode: 420
      name: argo-cd-redis-ha-configmap
    name: config-volume
  - emptyDir: {}
    name: shared-socket
  - emptyDir: {}
    name: data
  - name: kube-api-access-rwnn5
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2022-10-17T15:58:00Z"
    message: '0/2 nodes are available: 2 node(s) didn''t match pod affinity/anti-affinity
      rules, 2 node(s) didn''t match pod anti-affinity rules.'
    reason: Unschedulable
    status: "False"
    type: PodScheduled
  phase: Pending
  qosClass: BestEffort
